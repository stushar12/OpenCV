{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51510f12-5682-4542-bad6-7db509a64a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2787da65-fc68-46c0-b201-d14e4f47975b",
   "metadata": {},
   "source": [
    "\n",
    "# To read image from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b06b02c-db65-4071-ace9-b13d0661ce9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"xyz.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# Creating window to display an image on screen\n",
    "\n",
    "cv2.imshow(\"Sponge Bob\", img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c67e2b-0b6c-4453-99a9-75de64333dc8",
   "metadata": {},
   "source": [
    "# To read video from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c68f64-4284-4b0d-890b-41cab407ed9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "# Check if camera opened successfully\n",
    "if (cap.isOpened()== False):\n",
    "    print(\"Error opening video file\")\n",
    "\n",
    "# Read until video is completed\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == True:\n",
    "        cv2.imshow('Frame', frame)\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4eab14-8498-444d-aaa5-9f2d47bdb82f",
   "metadata": {},
   "source": [
    "# Capturing real time video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c74053-62db-4a63-b094-b60b7c5075fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = cv2.VideoCapture(0)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = vid.read()\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "           break\n",
    "\n",
    "\n",
    "vid.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c1c384-efc6-48cb-95c2-5f04cc3f12b2",
   "metadata": {},
   "source": [
    "# Basic Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfed9073-e726-4b9b-992a-3c9bdeffa6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting coloured image to gray image\n",
    "\n",
    "img = cv2.imread(\"xyz.png\")\n",
    "gray_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow(\"Gray_image\",gray_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81c1638-734c-4c36-a177-68fae0c55ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Blur the image\n",
    "\n",
    "img = cv2.imread(\"xyz.png\")\n",
    "blur_img=cv2.GaussianBlur(img,(21,21),0) # Parameter => (image,kernel(always odd),sigmaX)\n",
    "cv2.imshow(\"Blur_image\",blur_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ceda0c2-57d4-4065-9565-64b8d0c7aa03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Detection\n",
    "\n",
    "img = cv2.imread(\"xyz.png\")\n",
    "canny_img=cv2.Canny(img,100,50) # Parameter => (image,edge detection value) lower the value more the edges it detect\n",
    "cv2.imshow(\"Blur_image\",canny_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87310ea1-000c-4f20-b19a-901ab97125c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image Dilation after edge detection (making the edges thick)\n",
    "\n",
    "img = cv2.imread(\"xyz.png\")\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "canny_img=cv2.Canny(img,100,50) \n",
    "dilation_img=cv2.dilate(canny_img,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow(\"Dilate_image\",dilation_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687183c4-9fcf-493d-9553-6c8e9e39d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image erosion after Edge Detection (making the edges thin)\n",
    "\n",
    "img = cv2.imread(\"xyz.png\")\n",
    "kernel=np.ones((5,5),np.uint8)\n",
    "canny_img=cv2.Canny(img,100,50) \n",
    "eroded_img=cv2.erode(dilation_img,kernel,iterations=1)\n",
    "\n",
    "cv2.imshow(\"Erode_image\",eroded_img)\n",
    "cv2.waitKey(0) \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ffc5c5-07de-4115-992b-09059e8c5136",
   "metadata": {},
   "source": [
    "# Resizing and Cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843df796-cbc4-499f-8970-7dfa4be08e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding size of the image\n",
    "\n",
    "img = cv2.imread(\"xyz.png\", cv2.IMREAD_COLOR)\n",
    "print(img.shape)  #output format (height,width,colour)\n",
    "cv2.imshow(\"Sponge Bob\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7890afe-d642-4795-9d66-9984206fc144",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resize the size of image\n",
    "\n",
    "img = cv2.imread(\"xyz.png\", cv2.IMREAD_COLOR)\n",
    "resize_img=cv2.resize(img,(700,500))  #order is=>(width,height)\n",
    "print(resize_img.shape)\n",
    "cv2.imshow(\"Sponge Bob\", resize_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862d35d-855a-454e-a360-add027167ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cropping Image\n",
    "\n",
    "img = cv2.imread(\"xyz.png\", cv2.IMREAD_COLOR)\n",
    "cropped_image=img[70:500,450:750]  #order is=>(height,w idth)\n",
    "print(cropped_image.shape)\n",
    "cv2.imshow(\"Sponge Bob\", cropped_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d56a56-5f42-47bb-b8ce-62f92dc22a62",
   "metadata": {},
   "source": [
    "# Shapes and Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffc9f5d-a9ed-4bf0-bd8e-3d9df6a1934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making black image\n",
    "\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "img[150:350,100:400]=255,0,0     #color format => Blue Green Red\n",
    "cv2.imshow(\"Black\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812bc52b-9df1-4f2b-9210-c9bc42680c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making line on the image \n",
    "\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.line(img,(0,0),(512,512),(0,255,0),3)   #parmameters=> (starting point,ending point,color,thickness)\n",
    "cv2.line(img,(512,0),(0,512),(0,255,0),3)\n",
    "cv2.imshow(\"Black\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64949003-c255-47b8-85dd-2e8dbc95d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Making line on the rectangle\n",
    "    \n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.rectangle(img,(0,0),(256,256),(0,0,255),cv2.FILLED)#parmameters=> (starting point,diagonals,color,thickness)\n",
    "cv2.rectangle(img,(256,256),(512,512),(255,0,0),cv2.FILLED)\n",
    "cv2.rectangle(img,(0,256),(256,512),(0,255,0),cv2.FILLED)\n",
    "cv2.rectangle(img,(512,256),(256,0),(0,255,255),cv2.FILLED)    # x-axis and y-axis\n",
    "cv2.imshow(\"Black\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf713bd-e0df-4c69-8902-3948ef53132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making circle\n",
    "\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.circle(img,(256,256),150,(0,255,255),3)#parmameters=> (centre,radius,color,thickness)\n",
    "cv2.circle(img,(256,256),140,(0,0,255),3)\n",
    "cv2.circle(img,(256,256),130,(255,0,255),3)\n",
    "cv2.circle(img,(256,256),120,(255,255,0),3)\n",
    "cv2.circle(img,(256,256),110,(255,255,255),3)\n",
    "cv2.circle(img,(256,256),100,(0,255,0),3)\n",
    "cv2.circle(img,(256,256),90,(255,0,0),3)\n",
    "cv2.circle(img,(256,256),80,(127,127,127),3)\n",
    "cv2.imshow(\"Black\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efdbb64-25bf-4507-b734-1e5bd7ea340e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting text on image\n",
    "\n",
    "img=np.zeros((512,512,3),np.uint8)\n",
    "cv2.rectangle(img,(0,0),(256,256),(0,0,255),cv2.FILLED)#parmameters=> (img,starting point,diagonals,color,thickness)\n",
    "cv2.rectangle(img,(256,256),(512,512),(255,0,0),cv2.FILLED)\n",
    "cv2.rectangle(img,(0,256),(256,512),(0,255,0),cv2.FILLED)\n",
    "cv2.rectangle(img,(512,256),(256,0),(0,255,255),cv2.FILLED)    \n",
    "\n",
    "cv2.putText(img,\"RED\",(100,128),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),1) #parameter=> (img,text,text position,font,scale,color,thickness)\n",
    "cv2.putText(img,\"YELLOW\",(330,128),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),1)\n",
    "cv2.putText(img,\"GREEN\",(75,400),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),1)\n",
    "cv2.putText(img,\"BLUE\",(330,400),cv2.FONT_HERSHEY_COMPLEX,1,(0,0,0),1)\n",
    "cv2.imshow(\"Black\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6f08f-1001-4f7a-9f8e-452362df1ada",
   "metadata": {},
   "source": [
    "# Warp Perspective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa1732c-9a72-4c2b-a2a7-7d2fd330f864",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting view of a part of image from different perspective\n",
    "\n",
    "img=cv2.imread(\"king.jpg\")\n",
    "print(img.shape)\n",
    "\n",
    "width,height=250,350\n",
    "pts1=np.float32([[348,39],[489,103],[241,242],[385,314]])\n",
    "pts2=np.float32([[0,0],[width,0],[0,height],[width,height]])\n",
    "\n",
    "matrix=cv2.getPerspectiveTransform(pts1,pts2)\n",
    "img_output=cv2.warpPerspective(img,matrix,(width,height))\n",
    "\n",
    "cv2.imshow(\"King\", img_output)\n",
    "cv2.imshow(\"King_perspective\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d74796-3d7b-4047-83bc-f4be7af7965c",
   "metadata": {},
   "source": [
    "# Joining Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed15ac0-8b7c-418a-b746-d88dc8d1ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging two images\n",
    "\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]q\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "\n",
    "\n",
    "# horizontal_img=np.hstack((img,img))          Disadvantage with this function was that here size cannot be modified and also gray images \n",
    "# vertical_img=np.vstack((img,img))             images cannot be merged with coloured one\n",
    "# cv2.imshow(\"King_ver\", vertical_img)\n",
    "\n",
    "\n",
    "img=cv2.imread(\"king.jpg\")\n",
    "gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_stack=stackImages(0.5,[[img,gray,img],[gray,img,gray]])\n",
    "cv2.imshow(\"Stack Image\", img_stack)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc47042c-c3d3-4612-8e70-b4d504185068",
   "metadata": {},
   "source": [
    "# Color Detection in a Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a5ddc9-81b8-4243-bfc0-6c7d67dc1cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    " \n",
    "def empty(a):\n",
    "    pass\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    " \n",
    "cv2.namedWindow(\"TrackBars\",)\n",
    "cv2.resizeWindow(\"TrackBars\",640,240)\n",
    "cv2.createTrackbar(\"Hue Min\",\"TrackBars\",0,179,empty)\n",
    "cv2.createTrackbar(\"Hue Max\",\"TrackBars\",11,179,empty)\n",
    "cv2.createTrackbar(\"Sat Min\",\"TrackBars\",44,255,empty)\n",
    "cv2.createTrackbar(\"Sat Max\",\"TrackBars\",255,255,empty)\n",
    "cv2.createTrackbar(\"Val Min\",\"TrackBars\",52,255,empty)\n",
    "cv2.createTrackbar(\"Val Max\",\"TrackBars\",255,255,empty)\n",
    " \n",
    "while True:\n",
    "    img=cv2.imread('car.jpg')\n",
    "    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)\n",
    "    h_min = cv2.getTrackbarPos(\"Hue Min\",\"TrackBars\")\n",
    "    h_max = cv2.getTrackbarPos(\"Hue Max\", \"TrackBars\")\n",
    "    s_min = cv2.getTrackbarPos(\"Sat Min\", \"TrackBars\")\n",
    "    s_max = cv2.getTrackbarPos(\"Sat Max\", \"TrackBars\")\n",
    "    v_min = cv2.getTrackbarPos(\"Val Min\", \"TrackBars\")\n",
    "    v_max = cv2.getTrackbarPos(\"Val Max\", \"TrackBars\")\n",
    "    print(h_min,h_max,s_min,s_max,v_min,v_max)\n",
    "    lower = np.array([h_min,s_min,v_min])\n",
    "    upper = np.array([h_max,s_max,v_max])\n",
    "    mask = cv2.inRange(imgHSV,lower,upper)\n",
    "    imgResult = cv2.bitwise_and(img,img,mask=mask)\n",
    " \n",
    "    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))\n",
    "    cv2.imshow(\"Stacked Images\", imgStack)\n",
    "    if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f39f03e-befd-45d8-b2c0-8f42ebd0eda9",
   "metadata": {},
   "source": [
    "# Color Detection in a Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f64a626-7fe7-423d-887b-72b06e5626bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def stackImages(scale,imgArray):\n",
    "    rows = len(imgArray)\n",
    "    cols = len(imgArray[0])\n",
    "    rowsAvailable = isinstance(imgArray[0], list)\n",
    "    width = imgArray[0][0].shape[1]\n",
    "    height = imgArray[0][0].shape[0]\n",
    "    if rowsAvailable:\n",
    "        for x in range ( 0, rows):\n",
    "            for y in range(0, cols):\n",
    "                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)\n",
    "                else:\n",
    "                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)\n",
    "                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)\n",
    "        imageBlank = np.zeros((height, width, 3), np.uint8)\n",
    "        hor = [imageBlank]*rows\n",
    "        hor_con = [imageBlank]*rows\n",
    "        for x in range(0, rows):\n",
    "            hor[x] = np.hstack(imgArray[x])\n",
    "        ver = np.vstack(hor)\n",
    "    else:\n",
    "        for x in range(0, rows):\n",
    "            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)\n",
    "            else:\n",
    "                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)\n",
    "            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)\n",
    "        hor= np.hstack(imgArray)\n",
    "        ver = hor\n",
    "    return ver\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "      # Red color\n",
    "    low_red = np.array([0, 50, 50])\n",
    "    high_red = np.array([10, 255, 255])\n",
    "    red_mask = cv2.inRange(hsv_frame, low_red, high_red)\n",
    "    red = cv2.bitwise_and(frame, frame, mask=red_mask)\n",
    "    \n",
    "#     # Blue color\n",
    "    low_blue = np.array([94, 80, 2])\n",
    "    high_blue = np.array([126, 255, 255])\n",
    "    blue_mask = cv2.inRange(hsv_frame, low_blue, high_blue)\n",
    "    blue = cv2.bitwise_and(frame, frame, mask=blue_mask)\n",
    "\n",
    "\n",
    "#     # Green color\n",
    "    low_green = np.array([25, 52, 72])\n",
    "    high_green = np.array([102, 255, 255])\n",
    "    green_mask = cv2.inRange(hsv_frame, low_green, high_green)\n",
    "    green = cv2.bitwise_and(frame, frame, mask=green_mask)\n",
    "\n",
    "    # Every color except white\n",
    "    low = np.array([0, 42, 0])\n",
    "    high = np.array([179, 255, 255])\n",
    "    mask = cv2.inRange(hsv_frame, low, high)\n",
    "    result = cv2.bitwise_and(frame, frame, mask=mask)\n",
    "    \n",
    "    \n",
    "    imgStack = stackImages(0.5,([frame,result,red],[blue,green,frame]))\n",
    "    cv2.imshow(\"Stacked Images\", imgStack)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1213e087-6840-4cbf-832f-93bb6027df64",
   "metadata": {},
   "source": [
    "# Shapes and Contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91101df4-716f-4353-aa43-2027b1466f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "img=cv2.imread(\"shapes.jpg\")\n",
    "cv2.imshow(\"Shapes\",img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf27a7f-91bb-4799-997b-b65087f44544",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
